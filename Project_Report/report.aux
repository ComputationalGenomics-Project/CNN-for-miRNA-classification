\relax 
\citation{miRNA}
\citation{Convolutional-deep-belief}
\citation{CNN}
\citation{mirBase}
\citation{miRFam}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Formation and Function of microRNAs: generally, a miRNA molecule has two precursor molecules, pri-microRNA and pre-microRNA. In our model, we use mature miRNA sequences instead of these two precursor sequences. Sequence patterns (seed regions, mismatching regions) could be extracted for miRNA indentification.\relax }}{1}}
\citation{DNA-sequence-classification}
\citation{DNA-sequence-classification}
\citation{DNA-sequence-classification}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip LeNet Structure for Number Recognization: a LeNet contains convolution layers, max pooling layers and some fully-connected layers\relax }}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Word Sequences and Numerical Matrices}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip A simple illustration of one-hot vectorization of a sentence \nobreakspace  {}\cite  {DNA-sequence-classification}\relax }}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Deep Learning Neural Network}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Implementation details}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Generation}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Distribution of A, T, C and G in positive dataset}\relax }}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Distrubition of sequenc lengths in the positive dataset}\relax }}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sequence Vectorization}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 3-mer vectorization and Lookup table\relax }}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Input Data Processing}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sequence "TGAGGTAGTAGGTTGTATAGTT" vectorization (from the positive dataset)\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sequence "TGGAATGTAAAGAAGTATGTA" vectorization (from the positive dataset)\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Sequence "TGCTGGTTTCTTCCACAGTGGTA" vectorization (from the positive dataset)\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sequence "TCTTACTCATCCTATTCTTTAA" vectorization (from the negative dataset)\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Sequence "CATTAACCTTCATATTTCCTT" vectorization (from the negative dataset)\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Sequence "CATTTTAAATATTACCTCTATT" vectorization (from the negative dataset)\relax }}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Convolution Neural Networks}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Conclusions}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Training Record}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Training Record: The "YellowGreen line" indicates the training accuracy and the"Green line" indicates the cost(value of the loss function). The upper subfigure shows the record of a model with $\geq $ 98\% training accuracy while the bottom subfigure shows the record of a model with $\approx $ 50\% training accuracy.\relax }}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Performance}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Test accuracy: Convolution Neural Network (CNN) and Logistic Regression (LR)\relax }}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Discussion and Conclusions}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Code}{6}}
\bibcite{miRNA}{1}
\bibcite{Convolutional-deep-belief}{2}
\bibcite{CNN}{3}
\bibcite{mirBase}{4}
\bibcite{miRFam}{5}
\bibcite{DNA-sequence-classification}{6}
